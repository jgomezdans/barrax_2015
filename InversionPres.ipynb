{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Inferring the charactetistics of the surface from optical data\n",
    "### J GÃ³mez-Dans (NCEO & UCL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* RT theory allows us to explain the scattering & absorption of photons\n",
    "* ... by describing the optical properties and structure of the scene\n",
    "* However, we want to find out about the surface **from the data**!\n",
    "* E.g. we want to infer LAI, chlorophyll, ... from reflectrance measurements \n",
    "* The inverse problem...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The inverse problem\n",
    "* An RT model $\\mathcal{M}$ predicts directional reflectance factor, $\\vec{\\rho}_{m}(\\Omega, \\Omega')$\n",
    "    * \\dots as a function of a set of input parameters: LAI, chlorophyll concentration, equivalent leaf thickness...\n",
    "* Examples of $\\mathcal{M}$ are combinations of a leaf RT model, a canopy RT model and a soil RT model. Eg\n",
    "    * PROSPECT (Liberty?)\n",
    "    * SAIL (ACRM, Semidiscrete, ...)\n",
    "    * Linear mixture of spectra assuming Lambertian soil (Walthall, Hapke, ...)\n",
    "* We typically stack all input parameters into a vector $\\vec{x}$.\n",
    "* We also have other information available (e.g. illumination geometry, etc)\n",
    "\n",
    "$$\n",
    "\\mathcal{M}(\\mathbf{x}, I) = \\vec{\\rho}_m(\\Omega, \\Omega')\n",
    "$$\n",
    "\n",
    "* Our task is to infer $\\vec{x}$ given observations $\\vec{\\rho}(\\Omega, \\Omega')$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The model couples the observations and our parameters\n",
    "* In some cases, we might be able to provide an *analytic inversion*\n",
    "* However, we have ignored observational uncertainties\n",
    "* We have also ignored the model uncertainty (*inadequacy*): a model *is not* reality\n",
    "* These uncertainties will translate into uncertainty into our inference of $\\vec{x}$\n",
    "* Is there a framework for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###Reverend Bayes to the rescue\n",
    "\n",
    "<img src=\"http://rlv.zcache.com/reverend_thomas_bayes_coffee_mug-r832cba30bb8b4a73a6ed6dca65081329_x7jsg_8byvr_512.jpg\" width=\"40%\" height=\"20%\" /><img src=\"http://portrait.kaar.at/Naturwissenschaftler/images/pierre_simon_laplace.jpg\" width=\"45%\"  height=\"20%\"/>\n",
    "\n",
    "* We assume that parameter uncertainty can be encoded if we treat $\\vec{x}$ as a **probability density function** (pdf), $p(\\vec{x})$.\n",
    "* We are interested in learning about $p(\\vec{x})$ **conditional** on the observations $\\vec{R}$, $p(\\vec{x}|\\vec{R})$.\n",
    "* **Bayes' Rule** states how we can *learn* about $p(\\vec{x}|\\vec{R})$\n",
    "* In essence, Bayes' rule is a statement on how to *update our beliefs* on $\\vec{x}$ when new *evidence* crops up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "p(\\vec{x} | \\vec{R}, I ) =\\frac{ p (\\vec{R} | \\vec{x}, I)\\cdot p(\\vec{x},I)}{p(\\vec{R})}\\propto p (\\vec{R} | \\vec{x}, I)\\cdot p(\\vec{x},I) \n",
    "$$\n",
    "\n",
    "* $p(\\vec{R}|\\vec{x},I)$ is the **likelihood function**\n",
    "    * encodes the probability of $\\vec{R}$ **given** $\\vec{x}$, and any other information ($I$)\n",
    "* $p(\\vec{x})$ is our *a priori* belief in the pdf of $\\vec{x}$\n",
    "* $p(\\vec{R}$ can be thought of as normalisation constant, and we'll typically ignore it\n",
    "* A way to picture Bayes' rule:\n",
    "\n",
    "$$\n",
    "        p(\\textsf{Hypothesis} | \\textsf{Data},I) \\propto p(\\textsf{Data} | \\textsf{Hypothesis},I) \\times p(\\textsf{Hypothesis} | I)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The prior $p(\\vec{x})$\n",
    "\n",
    "* Encodes **everything we know** about $\\vec{x}$ before we even look at the data\n",
    "* In some cases, we can have *uninformative priors*...\n",
    "* ... but the real power is that it allows us to bring understanding, however weak to the problem!\n",
    "\n",
    "## The likelihood $p(\\vec{R}|\\vec{x})$\n",
    "\n",
    "* The likelihood states is our data generative model\n",
    "* It links the experimental results with the quantity of inference\n",
    "* It includes our observations, their uncertainties, but also the model and its uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Assume that we can model our observations using our RT model.\n",
    "\n",
    "$$\n",
    "\\vec{R} = \\mathcal{M}(\\vec{x}) + \\vec{\\epsilon}\n",
    "$$\n",
    "\n",
    "* We assume that there is a mismatch between what the model predicts and the measurements that is (in this case) *additive*, and given by $\\epsilon$\n",
    "* Assume that we have a perfect model\n",
    "    * The only possible mismatch is due to **experimental error**\n",
    "* Assume that the experimental error is e.g. Normal (Gaussian), ie $\\vec{\\epsilon}\\sim\\mathcal{N}(\\vec{\\mu}, \\mathbf{\\Sigma}_{obs})$, or assuming $\\vec{\\mu}=0$,\n",
    "\n",
    "$$\n",
    "\\vec{\\epsilon} = \\vec{R} - \\mathcal{M}(\\vec{x}) \\Rightarrow p(\\vec{R}|\\vec{x})\\propto \\exp\\left[ -\\frac{1}{2}\\left(\\vec{R}-\\mathcal{M}(\\vec{x}\\right)^\\top\\mathbf{\\Sigma}_{obs}^{-1}\\left(\\vec{R}-\\mathcal{M}(\\vec{x}\\right)\\right]\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
